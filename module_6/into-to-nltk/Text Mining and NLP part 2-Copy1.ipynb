{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Mining and NLP\n",
    "\n",
    "## Part 2\n",
    "\n",
    "### Situation:\n",
    "\n",
    "Priya works at an international PR firm in the Europe division. Their largest client has offices in Ibiza, Madrid, and Las Palmas. She needs to keep her boss aware of current events and provide a weekly short list of articles concerning political events in Spain. The problem is, this takes hours every week to review articles on the BBC and Priya is very busy! She wonders if she could automate this process using text mining to save her time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Goal**: to internalize the steps, challenges, and methodology of text mining\n",
    "- explore text analysis by hand\n",
    "- apply text mining steps in Jupyter with Python libraries NLTK\n",
    "- classify documents correctly"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Refresher on cleaning text\n",
    "![gif](https://www.nyfa.edu/student-resources/wp-content/uploads/2014/10/furious-crazed-typing.gif)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "\n",
    "import nltk\n",
    "import sklearn\n",
    "\n",
    "from nltk.collocations import *\n",
    "from nltk import FreqDist, word_tokenize\n",
    "import string, re\n",
    "import urllib\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "url_a = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/A.txt\"\n",
    "url_b = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/B.txt\"\n",
    "article_a = urllib.request.urlopen(url_a).read()\n",
    "article_a_st = article_a.decode(\"utf-8\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_char = ['A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K']\n",
    "file_list =[]\n",
    "for char in list_char:\n",
    "    name = \"https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/\" + char + \".txt\"\n",
    "    file_list.append(name)\n",
    "                     \n",
    "                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/A.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/B.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/C.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/D.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/E.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/F.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/G.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/H.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/I.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/J.txt',\n",
       " 'https://raw.githubusercontent.com/aapeebles/text_examples/master/Text%20examples%20folder/K.txt']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_char_list = []\n",
    "for element in file_list:\n",
    "    article_char = urllib.request.urlopen(element).read()\n",
    "    article_char_st = article_char.decode(\"utf-8\")\n",
    "    article_char_list.append(article_char_st)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Reboot ordered for EU patent law\\n\\nA European Parliament committee has ordered a rewrite of the proposals for controversial new European Union rules which govern computer-based inventions.\\n\\nThe Legal Affairs Committee (JURI) said the Commission should re-submit the Computer Implemented Inventions Directive after MEPs failed to back it. It has had vocal critics who say it could favour large over small firms and impact open-source software innovation. Supporters say it would let firms protect their inventions. The directive is intended to offer patent protection to inventions that use software to achieve their effect, in other words, \"computer implemented invention\". The draft law suffered setbacks when Poland, one of the largest EU member states, rejected its adoption twice in two months. Intense lobbying on the issue has started to gain momentum in some national parliaments putting them under immense pressure. Only two MEPs backed the draft law at the JURI meeting, with one voting to abstain.\\n\\nOpponents of the draft directive welcomed the decision and said a new first reading of the proposals would give the EU a chance to have fuller debates about its implications in all member states. In the US, the patenting of computer programs and internet business methods is permitted. This means that the US-based Amazon.com holds a patent for its \"one-click shopping\" service, for example. Critics are concerned that the directive could lead to a similar model happening in Europe. This, they fear, could hurt small software developers because they do not have the legal and financial might of larger companies if they had to fight patent legal action in court. Supporters say current laws are inefficient and it would serve to even up a playing field without bringing EU laws in line with the US.\\n',\n",
       " 'Tsunami debt deal to be announced\\n\\nChancellor Gordon Brown has said he hopes to announce a deal to suspend debt interest repayments by tsunami-hit nations later on Friday.\\n\\nThe agreement by the G8 group of wealthy nations would save affected countries £3bn pounds a year, he said. The deal is thought to have been hammered out on Thursday night after Japan, one of the biggest creditor nations, finally signed up to it. Mr Brown first proposed the idea earlier this week.\\n\\nG8 ministers are also believed to have agreed to instruct the World Bank and the International Monetary Fund to complete a country by country analysis of the reconstruction problems faced by all states hit by the disaster. Mr Brown has been locked in talks with finance ministers of the G8, which Britain now chairs. Germany also proposed a freeze and Canada has begun its own moratorium. The expected deal comes as Foreign Secretary Jack Straw said the number of Britons dead or missing in the disaster have reached 440.\\n',\n",
       " 'Sony PSP tipped as a \\'must-have\\'\\n\\nSony\\'s Playstation Portable is the top gadget for 2005, according to a round-up of ultimate gizmos compiled by Stuff Magazine.\\n\\nIt beats the iPod into second place in the Top Ten Essentials list which predicts what gadget-lovers are likely to covet this year. Owning all 10 gadgets will set the gadget lover back £7,455. That is £1,000 cheaper than last year\\'s list due to falling manufacturing costs making gadgets more affordable.\\n\\nPortable gadgets dominate the list, including Sharp\\'s 902 3G mobile phone, the Pentax Optio SV digital camera and Samsung\\'s Yepp YH-999 video jukebox.\\n\\n\"What this year\\'s Essentials shows is that gadgets are now cheaper, sexier and more indispensable than ever. We\\'ve got to the point where we can\\'t live our lives without certain technology,\" said Adam Vaughan, editor of Stuff Essentials. The proliferation of gadgets in our homes is inexorably altering the role of the high street in our lives thinks Mr Vaughan. \"Take digital cameras, who would now pay to develop an entire film of photos? Or legitimate downloads, who would travel miles to a record shop when they could download the song in minutes for 70p?\" he asks. Next year will see a new set of technologies capturing the imaginations of gadget lovers, Stuff predicts. The Xbox 2, high-definition TV and MP3 mobiles will be among the list of must-haves that will dominate 2006, it says. The spring launch of the PSP in the UK is eagerly awaited by gaming fans.\\n',\n",
       " 'BNP leader Nick Griffin arrested\\n\\nThe leader of the British National Party has been arrested as part of a police inquiry following the screening of a BBC documentary.\\n\\nA party spokesman said Nick Griffin was arrested on Tuesday morning on suspicion of incitement to commit racial hatred. West Yorkshire police confirmed they had arrested a 45-year-old man from outside their area. BNP founding chairman John Tyndall was arrested on Sunday on the same charge.\\n\\nIn July, the BBC documentary Secret Agent featured covertly-filmed footage of BNP activists. Mr Griffin is the twelfth man to be arrested following the documentary. Nine men from West Yorkshire and another man from Leicester have been arrested and freed on bail. Seven of the men had been held variously in connection with suspected racially aggravated public order offences, conspiracy to commit criminal damage and possession of a firearm. Two men, both from Keighley, were arrested in September on suspicion of conspiracy to commit criminal damage. A 24-year-old man from Leicester was detained on Monday on suspicion of incitement to commit racial hatred. A BNP spokesperson said Mr Tyndall, from Brighton, was arrested following a speech he made in Burnley, Lancashire, and was released on police bail.\\n',\n",
       " 'Security warning over \\'FBI virus\\'\\n\\nThe US Federal Bureau of Investigation is warning that a computer virus is being spread via e-mails that purport to be from the FBI.\\n\\nThe e-mails show that they have come from an fbi.gov address and tell recipients that they have accessed illegal websites. The messages warn that their internet use has been monitored by the FBI\\'s Internet Fraud Complaint Center. An attachment in the e-mail contains the virus, the FBI said. The message asks recipients to click on the attachment and answer some questions about their internet use. But rather than being a questionnaire, the attachment contains a virus that infects the recipient\\'s computer, according to the agency. It is not clear what the virus does once it has infected a computer. Users are warned never to open attachment from unsolicited e-mails or from people they do not know.\\n\\n\"Recipients of this or similar solicitations should know that the FBI does not engage in the practice of sending unsolicited e-mails to the public in this manner,\" the FBI said in a statement. The bureau is investigating the phoney e-mails. The agency earlier this month shut down fbi.gov accounts, used to communicate with the public, because of a security breach. A spokeswoman said the two incidents appear to be unrelated.\\n',\n",
       " \"O'Sullivan could run in Worlds\\n\\nSonia O'Sullivan has indicated that she would like to participate in next month's World Cross Country Championships in St Etienne.\\n\\nAthletics Ireland have hinted that the 35-year-old Cobh runner may be included in the official line-up for the event in France on 19-20 March. Provincial teams were selected after last Saturday's Nationals in Santry and will be officially announced this week. O'Sullivan is at present preparing for the London marathon on 17 April. The participation of O'Sullivan, currentily training at her base in Australia, would boost the Ireland team who won the bronze three years agio. The first three at Santry last Saturday, Jolene Byrne, Maria McCambridge and Fionnualla Britton, are automatic selections and will most likely form part of the long-course team. O'Sullivan will also take part in the Bupa Great Ireland Run on 9 April in Dublin.\\n\",\n",
       " \"Merritt close to indoor 400m mark\\n\\nTeenager LaShawn Merritt ran the third fastest indoor 400m of all time at the Fayetteville Invitational meeting.\\n\\nThe world junior champion clocked 44.93 seconds to finish well clear of fellow American Bershawn Jackson in Arkansas. Only Michael Johnson has gone quicker, setting the world record of 44.63secs in 1995 and running 44.66secs in 1996. Kenyan Bernard Lagat missed out on the world record by 1.45secs as he ran the third quickest indoor mile ever to beat Canada's Nate Brannen by almost 10secs. The Olympic silver medallist's time of three minutes 49.89secs was inferior only to the 1997 world record of Moroccan Hicham El Guerrouj and former world record holder Eamonn Coghlan of Ireland's 3:49.78. Lagat was on course to break El Guerrouj's record through 1200m but could not maintain the pace over the final 400m. Ireland's\\n\\ncontinued his excellent form by winning a tight 3,000m in 7:40.53. Cragg, who recently defeated Olympic 10,000m champion Kenenisa Bekele in Boston, held off Bekele's Ethiopian colleague Markos Geneti by only 0.19secs to secure his victory. Mark Carroll, who will join Cragg in the European Indoor Championships next month, finished a solid third in 7:46.78. Olympic 200m gold medallist\\n\\nof Jamaica ran the fastest women's 60m in the world this year as she equalled her personal best of 7.09secs. World indoor 60m hurdles champion\\n\\nalso won, improving his season-leading time to 7.51secs.\\n\",\n",
       " \"MPs quiz aides over royal income\\n\\nSenior officials at the two bodies generating private income for the Queen and Prince of Wales are to be questioned by MPs.\\n\\nAides from the Duchy of Lancaster and Duchy of Cornwall will appear before the Commons Public Accounts Committee. It has been reported they could be questioned about Prince Charles' spending on Camilla Parker Bowles. But BBC correspondent Peter Hunt said they are not responsible for how money is spent and may be unable to answer. Duchy officials, who will appear before the committee on Monday, are only responsible for generating money. The Duchy of Lancaster provides the Queen's private income, while the Duchy of Cornwall provides Prince Charles' annual income. The Duchy of Cornwall is a 140,000-acre estate across 25 counties, and also includes residential properties, shops, offices, stocks and shares. It was set up in 1337 by King Edward III to provide income for successive heirs to the throne. It covers the cost of the prince's public and private life - neither Charles, nor William and Harry, receive taxpayers' money from the Civil List. However, the Prince of Wales did receive over £4m from government departments and grants-in-aid in 2003-4. The duchy last year generated almost £12m. The prince has voluntarily paid income tax - currently 40% - since 1993.\\n\",\n",
       " 'Hotspot users gain free net calls\\n\\nPeople using wireless net hotspots will soon be able to make free phone calls as well as surf the net.\\n\\nWireless provider Broadreach and net telephony firm Skype are rolling out a service at 350 hotspots around the UK this week. Users will need a Skype account - downloadable for free - and they will then be able to make net calls via wi-fi without paying for net access. Skype allows people to make free PC-based calls to other Skype users.\\n\\nUsers of the system can also make calls to landlines and mobiles for a fee. The system is gaining in popularity and now has 28 million users around the world. Its paid service - dubbed Skype Out - has so far attracted 940,000 users. It plans to add more paid services with forthcoming launches of video conferencing, voice mail and Skype In, a service which would allow users to receive phone calls from landlines and mobiles. London-based software developer Connectotel has unveiled software that will expand the SMS functions of Skype, allowing users to send text messages to mobile phones from the service. Broadreach Networks has around two million users and hotspots in places such as Virgin Megastores, the Travelodge chain of hotels and all London\\'s major rail terminals. The company is due to launch wi-fi on Virgin Trains later in the year. \"Skype\\'s success at spreading the world about internet telephony is well-known and we are delighted to be offering free access to Skype users in our hotspots,\" commented Broadreach chief executive Magnus McEwen-King.\\n',\n",
       " 'Bekele sets sights on world mark\\n\\nOlympic 10,000m champion Kenenisa Bekele is determined to add the world indoor two mile record at February\\'s Norwich Union Grand Prix in Birmingham.\\n\\nThe 22-year-old will again be chasing a record held by his compatriot and mentor Haile Gebrselassie, who set the mark at the same meeting in 2003. \"I am still as hungry to do as much as I can in this sport,\" said Bekele. \"And aiming for the two mile world record in Birmingham is the next of those targets.\" Gebrselassie\\'s current record stands at eight minutes, 04.69 seconds. And Bekele is no stranger to overhauling world marks at the National Indoor Arena. The Ethiopian broke the world indoor 5,000m record on his debut at the meeting last year. Compatriots Mulugeta Wondimu, Abiyote Abate and Markos Geneti, the world indoor bronze medallist over 3000m, will race against Bekele on 18 February. The meet has already attracted a crop of Olympic talent. Britain\\'s 800m and 1500m champion Kelly Holmes is taking part in the 1000m. Swedish heptathlon gold medallist Carolina Kluft will contest the 60m hurdles. While men\\'s 4x100m relay gold medallists Jason Gardener and Mark Lewis-Francis will go head-to-head in the 60m.\\n',\n",
       " 'UK \\'needs true immigration data\\'\\n\\nA former Home Office minister has called for an independent body to be set up to monitor UK immigration.\\n\\nBarbara Roche said an organisation should monitor and publish figures and be independent of government. She said this would counter \"so-called independent\" groups like Migration Watch, which she described as an anti-immigration body posing as independent. Migration Watch says it is not against all immigration and the government already publishes accurate figures. Sir Andrew Green, chairman of the organisation, says there is no need for an independent body because Office of National Statistics data are accurate. He says he opposes large-scale immigration \"both on the grounds of overcrowding and culture\".\\n\\nHe said: \"For example, over the next 20 years one household in three will be due to immigration. \"We are already more overcrowded than India and we are four times more overcrowded than France.\" Ms Roche, Labour MP for Hornsey and Wood Green, believes legal migration is something we should welcome. She said her proposals mean \"we wouldn\\'t have so-called independent experts, like Migration Watch, who come into this debate from an anti-immigration point of view.\" She went on: \"What I would like to see is there being a body which actually looked at the figures, published them, and was independent of government. \"I think that would go a long way to allaying some of the fears that are sometimes whipped up during this debate.\"\\n']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "article_char_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_tokenize(file_list):\n",
    "    # tokens\n",
    "    \n",
    "    pattern = \"([a-zA-Z]+(?:'[a-z]+)?)\"\n",
    "    results = []\n",
    "        \n",
    "    arta_tokens_raw = nltk.regexp_tokenize(file_list, pattern)\n",
    "\n",
    "    # lower case\n",
    "    arta_tokens = [i.lower() for i in arta_tokens_raw]\n",
    "\n",
    "    # stop words\n",
    "    from nltk.corpus import stopwords\n",
    "    stopwords.words(\"english\")\n",
    "\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    arta_tokens_stopped = [w for w in arta_tokens if not w in stop_words]\n",
    "\n",
    "    # stem words\n",
    "    stemmer = SnowballStemmer(\"english\")\n",
    "    arta_stemmed = [stemmer.stem(word) for word in arta_tokens_stopped]\n",
    "    return arta_stemmed\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "expected string or bytes-like object",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-57c25e83bc52>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcleaned\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclean_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marticle_char_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-15-206f009890ad>\u001b[0m in \u001b[0;36mclean_tokenize\u001b[0;34m(file_list)\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0marta_tokens_raw\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mregexp_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;31m# lower case\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flatiron/lib/python3.7/site-packages/nltk/tokenize/regexp.py\u001b[0m in \u001b[0;36mregexp_tokenize\u001b[0;34m(text, pattern, gaps, discard_empty, flags)\u001b[0m\n\u001b[1;32m    217\u001b[0m     \"\"\"\n\u001b[1;32m    218\u001b[0m     \u001b[0mtokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRegexpTokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpattern\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgaps\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdiscard_empty\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 219\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    220\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/envs/flatiron/lib/python3.7/site-packages/nltk/tokenize/regexp.py\u001b[0m in \u001b[0;36mtokenize\u001b[0;34m(self, text)\u001b[0m\n\u001b[1;32m    134\u001b[0m         \u001b[0;31m# If our regexp matches tokens, use re.findall:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 136\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_regexp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfindall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mspan_tokenize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: expected string or bytes-like object"
     ]
    }
   ],
   "source": [
    "cleaned=clean_tokenize(article_char_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# repeat w second article\n",
    "article_b = urllib.request.urlopen(url_b).read()\n",
    "article_b_st = article_b.decode(\"utf-8\")\n",
    "artb_tokens_raw = nltk.regexp_tokenize(article_b_st, pattern)\n",
    "artb_tokens = [i.lower() for i in artb_tokens_raw]\n",
    "artb_tokens_stopped = [w for w in artb_tokens if not w in stop_words]\n",
    "artb_stemmed = [stemmer.stem(word) for word in artb_tokens_stopped]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "what's wrong with the table from yesterday? what does it not consider?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document Frequency (DF)\n",
    "\n",
    "$\\begin{align}\n",
    " tf_{i,j} = \\dfrac{n_{i,j}}{\\displaystyle \\sum_k n_{i,j} }\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inverse Document Frequency (IDF)\n",
    "\n",
    "$\\begin{align}\n",
    "idf(w) = \\log \\dfrac{N}{df_t}\n",
    "\\end{align} $"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DF-IDF score\n",
    "\n",
    "$ \\begin{align}\n",
    "w_{i,j} = tf_{i,j} \\times \\log \\dfrac{N}{df_i} \\\\\n",
    "tf_{i,j} = \\text{number of occurences of } i \\text{ in} j \\\\\n",
    "df_i = \\text{number of documents containing} i \\\\\n",
    "N = \\text{total number of documents}\n",
    "\\end{align} $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The from scratch method\n",
    "![homemade](https://media2.giphy.com/media/LBZcXdG0eVBdK/giphy.gif?cid=3640f6095c2d7bb2526a424a4d97117c)\n",
    "\n",
    "\n",
    "Please go through the code and comment what each section does"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'abstain',\n",
       " 'achiev',\n",
       " 'action',\n",
       " 'adopt',\n",
       " 'affair',\n",
       " 'affect',\n",
       " 'agre',\n",
       " 'agreement',\n",
       " 'also',\n",
       " 'amazon',\n",
       " 'analysi',\n",
       " 'announc',\n",
       " 'back',\n",
       " 'bank',\n",
       " 'base',\n",
       " 'begun',\n",
       " 'believ',\n",
       " 'biggest',\n",
       " 'bn',\n",
       " 'bring',\n",
       " 'britain',\n",
       " 'briton',\n",
       " 'brown',\n",
       " 'busi',\n",
       " 'canada',\n",
       " 'chair',\n",
       " 'chanc',\n",
       " 'chancellor',\n",
       " 'click',\n",
       " 'com',\n",
       " 'come',\n",
       " 'commiss',\n",
       " 'committe',\n",
       " 'compani',\n",
       " 'complet',\n",
       " 'comput',\n",
       " 'concern',\n",
       " 'controversi',\n",
       " 'could',\n",
       " 'countri',\n",
       " 'court',\n",
       " 'creditor',\n",
       " 'critic',\n",
       " 'current',\n",
       " 'dead',\n",
       " 'deal',\n",
       " 'debat',\n",
       " 'debt',\n",
       " 'decis',\n",
       " 'develop',\n",
       " 'direct',\n",
       " 'disast',\n",
       " 'draft',\n",
       " 'earlier',\n",
       " 'effect',\n",
       " 'eu',\n",
       " 'europ',\n",
       " 'european',\n",
       " 'even',\n",
       " 'exampl',\n",
       " 'expect',\n",
       " 'face',\n",
       " 'fail',\n",
       " 'favour',\n",
       " 'fear',\n",
       " 'field',\n",
       " 'fight',\n",
       " 'final',\n",
       " 'financ',\n",
       " 'financi',\n",
       " 'firm',\n",
       " 'first',\n",
       " 'foreign',\n",
       " 'freez',\n",
       " 'friday',\n",
       " 'fuller',\n",
       " 'fund',\n",
       " 'g',\n",
       " 'gain',\n",
       " 'germani',\n",
       " 'give',\n",
       " 'gordon',\n",
       " 'govern',\n",
       " 'group',\n",
       " 'hammer',\n",
       " 'happen',\n",
       " 'hit',\n",
       " 'hold',\n",
       " 'hope',\n",
       " 'hurt',\n",
       " 'idea',\n",
       " 'immens',\n",
       " 'impact',\n",
       " 'implement',\n",
       " 'implic',\n",
       " 'ineffici',\n",
       " 'innov',\n",
       " 'instruct',\n",
       " 'intend',\n",
       " 'intens',\n",
       " 'interest',\n",
       " 'intern',\n",
       " 'internet',\n",
       " 'invent',\n",
       " 'issu',\n",
       " 'jack',\n",
       " 'japan',\n",
       " 'juri',\n",
       " 'larg',\n",
       " 'larger',\n",
       " 'largest',\n",
       " 'later',\n",
       " 'law',\n",
       " 'lead',\n",
       " 'legal',\n",
       " 'let',\n",
       " 'line',\n",
       " 'lobbi',\n",
       " 'lock',\n",
       " 'mean',\n",
       " 'meet',\n",
       " 'member',\n",
       " 'mep',\n",
       " 'method',\n",
       " 'might',\n",
       " 'minist',\n",
       " 'miss',\n",
       " 'model',\n",
       " 'momentum',\n",
       " 'monetari',\n",
       " 'month',\n",
       " 'moratorium',\n",
       " 'mr',\n",
       " 'nation',\n",
       " 'new',\n",
       " 'night',\n",
       " 'number',\n",
       " 'offer',\n",
       " 'one',\n",
       " 'open',\n",
       " 'oppon',\n",
       " 'order',\n",
       " 'parliament',\n",
       " 'patent',\n",
       " 'permit',\n",
       " 'play',\n",
       " 'poland',\n",
       " 'pound',\n",
       " 'pressur',\n",
       " 'problem',\n",
       " 'program',\n",
       " 'propos',\n",
       " 'protect',\n",
       " 'put',\n",
       " 'reach',\n",
       " 'read',\n",
       " 'reboot',\n",
       " 'reconstruct',\n",
       " 'reject',\n",
       " 'repay',\n",
       " 'rewrit',\n",
       " 'rule',\n",
       " 'said',\n",
       " 'save',\n",
       " 'say',\n",
       " 'secretari',\n",
       " 'serv',\n",
       " 'servic',\n",
       " 'setback',\n",
       " 'shop',\n",
       " 'sign',\n",
       " 'similar',\n",
       " 'small',\n",
       " 'softwar',\n",
       " 'sourc',\n",
       " 'start',\n",
       " 'state',\n",
       " 'straw',\n",
       " 'submit',\n",
       " 'suffer',\n",
       " 'support',\n",
       " 'suspend',\n",
       " 'talk',\n",
       " 'thought',\n",
       " 'thursday',\n",
       " 'tsunami',\n",
       " 'twice',\n",
       " 'two',\n",
       " 'union',\n",
       " 'us',\n",
       " 'use',\n",
       " 'vocal',\n",
       " 'vote',\n",
       " 'wealthi',\n",
       " 'week',\n",
       " 'welcom',\n",
       " 'without',\n",
       " 'word',\n",
       " 'world',\n",
       " 'would',\n",
       " 'year'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordSet = set(arta_stemmed).union(set(artb_stemmed))\n",
    "# Join all non_repeated(i.e. set) words from ararta_stemmed and artbartb_stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adopt': 0,\n",
       " 'secretari': 0,\n",
       " 'offer': 0,\n",
       " 'base': 0,\n",
       " 'gain': 0,\n",
       " 'lobbi': 0,\n",
       " 'problem': 0,\n",
       " 'intern': 0,\n",
       " 'straw': 0,\n",
       " 'intend': 0,\n",
       " 'twice': 0,\n",
       " 'servic': 0,\n",
       " 'govern': 0,\n",
       " 'biggest': 0,\n",
       " 'exampl': 0,\n",
       " 'interest': 0,\n",
       " 'current': 0,\n",
       " 'japan': 0,\n",
       " 'wealthi': 0,\n",
       " 'rewrit': 0,\n",
       " 'month': 0,\n",
       " 'friday': 0,\n",
       " 'line': 0,\n",
       " 'debat': 0,\n",
       " 'expect': 0,\n",
       " 'hammer': 0,\n",
       " 'put': 0,\n",
       " 'pressur': 0,\n",
       " 'hope': 0,\n",
       " 'fund': 0,\n",
       " 'agre': 0,\n",
       " 'repay': 0,\n",
       " 'softwar': 0,\n",
       " 'action': 0,\n",
       " 'canada': 0,\n",
       " 'happen': 0,\n",
       " 'commiss': 0,\n",
       " 'hurt': 0,\n",
       " 'us': 0,\n",
       " 'might': 0,\n",
       " 'amazon': 0,\n",
       " 'program': 0,\n",
       " 'abstain': 0,\n",
       " 'monetari': 0,\n",
       " 'suffer': 0,\n",
       " 'moratorium': 0,\n",
       " 'critic': 0,\n",
       " 'dead': 0,\n",
       " 'submit': 0,\n",
       " 'also': 0,\n",
       " 'reach': 0,\n",
       " 'bring': 0,\n",
       " 'law': 0,\n",
       " 'foreign': 0,\n",
       " 'order': 0,\n",
       " 'pound': 0,\n",
       " 'give': 0,\n",
       " 'mean': 0,\n",
       " 'analysi': 0,\n",
       " 'thought': 0,\n",
       " 'larger': 0,\n",
       " 'lead': 0,\n",
       " 'firm': 0,\n",
       " 'welcom': 0,\n",
       " 'even': 0,\n",
       " 'court': 0,\n",
       " 'comput': 0,\n",
       " 'click': 0,\n",
       " 'play': 0,\n",
       " 'affair': 0,\n",
       " 'parliament': 0,\n",
       " 'chancellor': 0,\n",
       " 'earlier': 0,\n",
       " 'serv': 0,\n",
       " 'legal': 0,\n",
       " 'field': 0,\n",
       " 'setback': 0,\n",
       " 'immens': 0,\n",
       " 'later': 0,\n",
       " 'financ': 0,\n",
       " 'larg': 0,\n",
       " 'said': 0,\n",
       " 'oppon': 0,\n",
       " 'tsunami': 0,\n",
       " 'come': 0,\n",
       " 'idea': 0,\n",
       " 'could': 0,\n",
       " 'favour': 0,\n",
       " 'impact': 0,\n",
       " 'week': 0,\n",
       " 'mep': 0,\n",
       " 'two': 0,\n",
       " 'without': 0,\n",
       " 'union': 0,\n",
       " 'controversi': 0,\n",
       " 'chanc': 0,\n",
       " 'momentum': 0,\n",
       " 'fear': 0,\n",
       " 'mr': 0,\n",
       " 'achiev': 0,\n",
       " 'compani': 0,\n",
       " 'let': 0,\n",
       " 'juri': 0,\n",
       " 'countri': 0,\n",
       " 'debt': 0,\n",
       " 'miss': 0,\n",
       " 'minist': 0,\n",
       " 'state': 0,\n",
       " 'invent': 0,\n",
       " 'lock': 0,\n",
       " 'briton': 0,\n",
       " 'issu': 0,\n",
       " 'reject': 0,\n",
       " 'affect': 0,\n",
       " 'vote': 0,\n",
       " 'fail': 0,\n",
       " 'method': 0,\n",
       " 'implic': 0,\n",
       " 'bn': 0,\n",
       " 'would': 0,\n",
       " 'eu': 0,\n",
       " 'propos': 0,\n",
       " 'announc': 0,\n",
       " 'implement': 0,\n",
       " 'similar': 0,\n",
       " 'thursday': 0,\n",
       " 'complet': 0,\n",
       " 'hold': 0,\n",
       " 'open': 0,\n",
       " 'busi': 0,\n",
       " 'reboot': 0,\n",
       " 'save': 0,\n",
       " 'creditor': 0,\n",
       " 'nation': 0,\n",
       " 'shop': 0,\n",
       " 'financi': 0,\n",
       " 'suspend': 0,\n",
       " 'start': 0,\n",
       " 'poland': 0,\n",
       " 'european': 0,\n",
       " 'brown': 0,\n",
       " 'member': 0,\n",
       " 'use': 0,\n",
       " 'fuller': 0,\n",
       " 'intens': 0,\n",
       " 'final': 0,\n",
       " 'britain': 0,\n",
       " 'face': 0,\n",
       " 'back': 0,\n",
       " 'read': 0,\n",
       " 'europ': 0,\n",
       " 'new': 0,\n",
       " 'one': 0,\n",
       " 'effect': 0,\n",
       " 'deal': 0,\n",
       " 'sign': 0,\n",
       " 'freez': 0,\n",
       " 'internet': 0,\n",
       " 'night': 0,\n",
       " 'talk': 0,\n",
       " 'begun': 0,\n",
       " 'direct': 0,\n",
       " 'develop': 0,\n",
       " 'chair': 0,\n",
       " 'fight': 0,\n",
       " 'support': 0,\n",
       " 'largest': 0,\n",
       " 'permit': 0,\n",
       " 'bank': 0,\n",
       " 'innov': 0,\n",
       " 'reconstruct': 0,\n",
       " 'world': 0,\n",
       " 'concern': 0,\n",
       " 'instruct': 0,\n",
       " 'small': 0,\n",
       " 'say': 0,\n",
       " 'protect': 0,\n",
       " 'agreement': 0,\n",
       " 'germani': 0,\n",
       " 'ineffici': 0,\n",
       " 'committe': 0,\n",
       " 'number': 0,\n",
       " 'word': 0,\n",
       " 'sourc': 0,\n",
       " 'model': 0,\n",
       " 'disast': 0,\n",
       " 'gordon': 0,\n",
       " 'group': 0,\n",
       " 'hit': 0,\n",
       " 'patent': 0,\n",
       " 'vocal': 0,\n",
       " 'first': 0,\n",
       " 'meet': 0,\n",
       " 'rule': 0,\n",
       " 'decis': 0,\n",
       " 'com': 0,\n",
       " 'jack': 0,\n",
       " 'g': 0,\n",
       " 'believ': 0,\n",
       " 'draft': 0,\n",
       " 'year': 0}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordDictA = dict.fromkeys(wordSet, 0) \n",
    "# Set all dicts values to 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "wordDictB = dict.fromkeys(wordSet, 0) \n",
    "# Set all dicts values to 0\n",
    "\n",
    "# Getting the count for all existing keys in wordDictA\n",
    "for word in arta_stemmed:\n",
    "    wordDictA[word]+=1\n",
    "\n",
    "#Getting the count for all existing keys in wordDictB\n",
    "for word in artb_stemmed:\n",
    "    wordDictB[word]+=1    \n",
    "\n",
    "#Getting the percentage of word frequency     \n",
    "def computeTF(wordDict, bow):\n",
    "    tfDict = {}\n",
    "    bowCount = len(bow)\n",
    "    for word, count in wordDict.items():\n",
    "        tfDict[word] = count/bowCount\n",
    "    return tfDict\n",
    "\n",
    "# assign percentage of word frequencies in two varibales\n",
    "tfbowA = computeTF(wordDictA,arta_stemmed)\n",
    "tfbowB = computeTF(wordDictB,artb_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adopt': 0.021739130434782608,\n",
       " 'secretari': 0.0,\n",
       " 'offer': 0.021739130434782608,\n",
       " 'base': 0.043478260869565216,\n",
       " 'gain': 0.021739130434782608,\n",
       " 'lobbi': 0.021739130434782608,\n",
       " 'problem': 0.0,\n",
       " 'intern': 0.0,\n",
       " 'straw': 0.0,\n",
       " 'intend': 0.021739130434782608,\n",
       " 'twice': 0.021739130434782608,\n",
       " 'servic': 0.021739130434782608,\n",
       " 'govern': 0.021739130434782608,\n",
       " 'biggest': 0.0,\n",
       " 'exampl': 0.021739130434782608,\n",
       " 'interest': 0.0,\n",
       " 'current': 0.021739130434782608,\n",
       " 'japan': 0.0,\n",
       " 'wealthi': 0.0,\n",
       " 'rewrit': 0.021739130434782608,\n",
       " 'month': 0.021739130434782608,\n",
       " 'friday': 0.0,\n",
       " 'line': 0.021739130434782608,\n",
       " 'debat': 0.021739130434782608,\n",
       " 'expect': 0.0,\n",
       " 'hammer': 0.0,\n",
       " 'put': 0.021739130434782608,\n",
       " 'pressur': 0.021739130434782608,\n",
       " 'hope': 0.0,\n",
       " 'fund': 0.0,\n",
       " 'agre': 0.0,\n",
       " 'repay': 0.0,\n",
       " 'softwar': 0.06521739130434782,\n",
       " 'action': 0.021739130434782608,\n",
       " 'canada': 0.0,\n",
       " 'happen': 0.021739130434782608,\n",
       " 'commiss': 0.021739130434782608,\n",
       " 'hurt': 0.021739130434782608,\n",
       " 'us': 0.06521739130434782,\n",
       " 'might': 0.021739130434782608,\n",
       " 'amazon': 0.021739130434782608,\n",
       " 'program': 0.021739130434782608,\n",
       " 'abstain': 0.021739130434782608,\n",
       " 'monetari': 0.0,\n",
       " 'suffer': 0.021739130434782608,\n",
       " 'moratorium': 0.0,\n",
       " 'critic': 0.043478260869565216,\n",
       " 'dead': 0.0,\n",
       " 'submit': 0.021739130434782608,\n",
       " 'also': 0.0,\n",
       " 'reach': 0.0,\n",
       " 'bring': 0.021739130434782608,\n",
       " 'law': 0.10869565217391304,\n",
       " 'foreign': 0.0,\n",
       " 'order': 0.043478260869565216,\n",
       " 'pound': 0.0,\n",
       " 'give': 0.021739130434782608,\n",
       " 'mean': 0.021739130434782608,\n",
       " 'analysi': 0.0,\n",
       " 'thought': 0.0,\n",
       " 'larger': 0.021739130434782608,\n",
       " 'lead': 0.021739130434782608,\n",
       " 'firm': 0.043478260869565216,\n",
       " 'welcom': 0.021739130434782608,\n",
       " 'even': 0.021739130434782608,\n",
       " 'court': 0.021739130434782608,\n",
       " 'comput': 0.08695652173913043,\n",
       " 'click': 0.021739130434782608,\n",
       " 'play': 0.021739130434782608,\n",
       " 'affair': 0.021739130434782608,\n",
       " 'parliament': 0.043478260869565216,\n",
       " 'chancellor': 0.0,\n",
       " 'earlier': 0.0,\n",
       " 'serv': 0.021739130434782608,\n",
       " 'legal': 0.06521739130434782,\n",
       " 'field': 0.021739130434782608,\n",
       " 'setback': 0.021739130434782608,\n",
       " 'immens': 0.021739130434782608,\n",
       " 'later': 0.0,\n",
       " 'financ': 0.0,\n",
       " 'larg': 0.021739130434782608,\n",
       " 'said': 0.043478260869565216,\n",
       " 'oppon': 0.021739130434782608,\n",
       " 'tsunami': 0.0,\n",
       " 'come': 0.0,\n",
       " 'idea': 0.0,\n",
       " 'could': 0.06521739130434782,\n",
       " 'favour': 0.021739130434782608,\n",
       " 'impact': 0.021739130434782608,\n",
       " 'week': 0.0,\n",
       " 'mep': 0.043478260869565216,\n",
       " 'two': 0.043478260869565216,\n",
       " 'without': 0.021739130434782608,\n",
       " 'union': 0.021739130434782608,\n",
       " 'controversi': 0.021739130434782608,\n",
       " 'chanc': 0.021739130434782608,\n",
       " 'momentum': 0.021739130434782608,\n",
       " 'fear': 0.021739130434782608,\n",
       " 'mr': 0.0,\n",
       " 'achiev': 0.021739130434782608,\n",
       " 'compani': 0.021739130434782608,\n",
       " 'let': 0.021739130434782608,\n",
       " 'juri': 0.043478260869565216,\n",
       " 'countri': 0.0,\n",
       " 'debt': 0.0,\n",
       " 'miss': 0.0,\n",
       " 'minist': 0.0,\n",
       " 'state': 0.043478260869565216,\n",
       " 'invent': 0.10869565217391304,\n",
       " 'lock': 0.0,\n",
       " 'briton': 0.0,\n",
       " 'issu': 0.021739130434782608,\n",
       " 'reject': 0.021739130434782608,\n",
       " 'affect': 0.0,\n",
       " 'vote': 0.021739130434782608,\n",
       " 'fail': 0.021739130434782608,\n",
       " 'method': 0.021739130434782608,\n",
       " 'implic': 0.021739130434782608,\n",
       " 'bn': 0.0,\n",
       " 'would': 0.06521739130434782,\n",
       " 'eu': 0.08695652173913043,\n",
       " 'propos': 0.043478260869565216,\n",
       " 'announc': 0.0,\n",
       " 'implement': 0.043478260869565216,\n",
       " 'similar': 0.021739130434782608,\n",
       " 'thursday': 0.0,\n",
       " 'complet': 0.0,\n",
       " 'hold': 0.021739130434782608,\n",
       " 'open': 0.021739130434782608,\n",
       " 'busi': 0.021739130434782608,\n",
       " 'reboot': 0.021739130434782608,\n",
       " 'save': 0.0,\n",
       " 'creditor': 0.0,\n",
       " 'nation': 0.021739130434782608,\n",
       " 'shop': 0.021739130434782608,\n",
       " 'financi': 0.021739130434782608,\n",
       " 'suspend': 0.0,\n",
       " 'start': 0.021739130434782608,\n",
       " 'poland': 0.021739130434782608,\n",
       " 'european': 0.043478260869565216,\n",
       " 'brown': 0.0,\n",
       " 'member': 0.043478260869565216,\n",
       " 'use': 0.021739130434782608,\n",
       " 'fuller': 0.021739130434782608,\n",
       " 'intens': 0.021739130434782608,\n",
       " 'final': 0.0,\n",
       " 'britain': 0.0,\n",
       " 'face': 0.0,\n",
       " 'back': 0.043478260869565216,\n",
       " 'read': 0.021739130434782608,\n",
       " 'europ': 0.021739130434782608,\n",
       " 'new': 0.043478260869565216,\n",
       " 'one': 0.06521739130434782,\n",
       " 'effect': 0.021739130434782608,\n",
       " 'deal': 0.0,\n",
       " 'sign': 0.0,\n",
       " 'freez': 0.0,\n",
       " 'internet': 0.021739130434782608,\n",
       " 'night': 0.0,\n",
       " 'talk': 0.0,\n",
       " 'begun': 0.0,\n",
       " 'direct': 0.08695652173913043,\n",
       " 'develop': 0.021739130434782608,\n",
       " 'chair': 0.0,\n",
       " 'fight': 0.021739130434782608,\n",
       " 'support': 0.043478260869565216,\n",
       " 'largest': 0.021739130434782608,\n",
       " 'permit': 0.021739130434782608,\n",
       " 'bank': 0.0,\n",
       " 'innov': 0.021739130434782608,\n",
       " 'reconstruct': 0.0,\n",
       " 'world': 0.0,\n",
       " 'concern': 0.021739130434782608,\n",
       " 'instruct': 0.0,\n",
       " 'small': 0.043478260869565216,\n",
       " 'say': 0.06521739130434782,\n",
       " 'protect': 0.043478260869565216,\n",
       " 'agreement': 0.0,\n",
       " 'germani': 0.0,\n",
       " 'ineffici': 0.021739130434782608,\n",
       " 'committe': 0.043478260869565216,\n",
       " 'number': 0.0,\n",
       " 'word': 0.021739130434782608,\n",
       " 'sourc': 0.021739130434782608,\n",
       " 'model': 0.021739130434782608,\n",
       " 'disast': 0.0,\n",
       " 'gordon': 0.0,\n",
       " 'group': 0.0,\n",
       " 'hit': 0.0,\n",
       " 'patent': 0.10869565217391304,\n",
       " 'vocal': 0.021739130434782608,\n",
       " 'first': 0.021739130434782608,\n",
       " 'meet': 0.021739130434782608,\n",
       " 'rule': 0.021739130434782608,\n",
       " 'decis': 0.021739130434782608,\n",
       " 'com': 0.021739130434782608,\n",
       " 'jack': 0.0,\n",
       " 'g': 0.0,\n",
       " 'believ': 0.0,\n",
       " 'draft': 0.06521739130434782,\n",
       " 'year': 0.0}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'adopt': 0.016304347826086956,\n",
       " 'secretari': 0.0,\n",
       " 'offer': 0.016304347826086956,\n",
       " 'base': 0.03260869565217391,\n",
       " 'gain': 0.016304347826086956,\n",
       " 'lobbi': 0.016304347826086956,\n",
       " 'problem': 0.0,\n",
       " 'intern': 0.0,\n",
       " 'straw': 0.0,\n",
       " 'intend': 0.016304347826086956,\n",
       " 'twice': 0.016304347826086956,\n",
       " 'servic': 0.016304347826086956,\n",
       " 'govern': 0.016304347826086956,\n",
       " 'biggest': 0.0,\n",
       " 'exampl': 0.016304347826086956,\n",
       " 'interest': 0.0,\n",
       " 'current': 0.016304347826086956,\n",
       " 'japan': 0.0,\n",
       " 'wealthi': 0.0,\n",
       " 'rewrit': 0.016304347826086956,\n",
       " 'month': 0.016304347826086956,\n",
       " 'friday': 0.0,\n",
       " 'line': 0.016304347826086956,\n",
       " 'debat': 0.016304347826086956,\n",
       " 'expect': 0.0,\n",
       " 'hammer': 0.0,\n",
       " 'put': 0.016304347826086956,\n",
       " 'pressur': 0.016304347826086956,\n",
       " 'hope': 0.0,\n",
       " 'fund': 0.0,\n",
       " 'agre': 0.0,\n",
       " 'repay': 0.0,\n",
       " 'softwar': 0.04891304347826087,\n",
       " 'action': 0.016304347826086956,\n",
       " 'canada': 0.0,\n",
       " 'happen': 0.016304347826086956,\n",
       " 'commiss': 0.016304347826086956,\n",
       " 'hurt': 0.016304347826086956,\n",
       " 'us': 0.04891304347826087,\n",
       " 'might': 0.016304347826086956,\n",
       " 'amazon': 0.016304347826086956,\n",
       " 'program': 0.016304347826086956,\n",
       " 'abstain': 0.016304347826086956,\n",
       " 'monetari': 0.0,\n",
       " 'suffer': 0.016304347826086956,\n",
       " 'moratorium': 0.0,\n",
       " 'critic': 0.03260869565217391,\n",
       " 'dead': 0.0,\n",
       " 'submit': 0.016304347826086956,\n",
       " 'also': 0.0,\n",
       " 'reach': 0.0,\n",
       " 'bring': 0.016304347826086956,\n",
       " 'law': 0.08152173913043478,\n",
       " 'foreign': 0.0,\n",
       " 'order': 0.03260869565217391,\n",
       " 'pound': 0.0,\n",
       " 'give': 0.016304347826086956,\n",
       " 'mean': 0.016304347826086956,\n",
       " 'analysi': 0.0,\n",
       " 'thought': 0.0,\n",
       " 'larger': 0.016304347826086956,\n",
       " 'lead': 0.016304347826086956,\n",
       " 'firm': 0.03260869565217391,\n",
       " 'welcom': 0.016304347826086956,\n",
       " 'even': 0.016304347826086956,\n",
       " 'court': 0.016304347826086956,\n",
       " 'comput': 0.06521739130434782,\n",
       " 'click': 0.016304347826086956,\n",
       " 'play': 0.016304347826086956,\n",
       " 'affair': 0.016304347826086956,\n",
       " 'parliament': 0.03260869565217391,\n",
       " 'chancellor': 0.0,\n",
       " 'earlier': 0.0,\n",
       " 'serv': 0.016304347826086956,\n",
       " 'legal': 0.04891304347826087,\n",
       " 'field': 0.016304347826086956,\n",
       " 'setback': 0.016304347826086956,\n",
       " 'immens': 0.016304347826086956,\n",
       " 'later': 0.0,\n",
       " 'financ': 0.0,\n",
       " 'larg': 0.016304347826086956,\n",
       " 'said': 0.03260869565217391,\n",
       " 'oppon': 0.016304347826086956,\n",
       " 'tsunami': 0.0,\n",
       " 'come': 0.0,\n",
       " 'idea': 0.0,\n",
       " 'could': 0.04891304347826087,\n",
       " 'favour': 0.016304347826086956,\n",
       " 'impact': 0.016304347826086956,\n",
       " 'week': 0.0,\n",
       " 'mep': 0.03260869565217391,\n",
       " 'two': 0.03260869565217391,\n",
       " 'without': 0.016304347826086956,\n",
       " 'union': 0.016304347826086956,\n",
       " 'controversi': 0.016304347826086956,\n",
       " 'chanc': 0.016304347826086956,\n",
       " 'momentum': 0.016304347826086956,\n",
       " 'fear': 0.016304347826086956,\n",
       " 'mr': 0.0,\n",
       " 'achiev': 0.016304347826086956,\n",
       " 'compani': 0.016304347826086956,\n",
       " 'let': 0.016304347826086956,\n",
       " 'juri': 0.03260869565217391,\n",
       " 'countri': 0.0,\n",
       " 'debt': 0.0,\n",
       " 'miss': 0.0,\n",
       " 'minist': 0.0,\n",
       " 'state': 0.03260869565217391,\n",
       " 'invent': 0.08152173913043478,\n",
       " 'lock': 0.0,\n",
       " 'briton': 0.0,\n",
       " 'issu': 0.016304347826086956,\n",
       " 'reject': 0.016304347826086956,\n",
       " 'affect': 0.0,\n",
       " 'vote': 0.016304347826086956,\n",
       " 'fail': 0.016304347826086956,\n",
       " 'method': 0.016304347826086956,\n",
       " 'implic': 0.016304347826086956,\n",
       " 'bn': 0.0,\n",
       " 'would': 0.04891304347826087,\n",
       " 'eu': 0.06521739130434782,\n",
       " 'propos': 0.03260869565217391,\n",
       " 'announc': 0.0,\n",
       " 'implement': 0.03260869565217391,\n",
       " 'similar': 0.016304347826086956,\n",
       " 'thursday': 0.0,\n",
       " 'complet': 0.0,\n",
       " 'hold': 0.016304347826086956,\n",
       " 'open': 0.016304347826086956,\n",
       " 'busi': 0.016304347826086956,\n",
       " 'reboot': 0.016304347826086956,\n",
       " 'save': 0.0,\n",
       " 'creditor': 0.0,\n",
       " 'nation': 0.016304347826086956,\n",
       " 'shop': 0.016304347826086956,\n",
       " 'financi': 0.016304347826086956,\n",
       " 'suspend': 0.0,\n",
       " 'start': 0.016304347826086956,\n",
       " 'poland': 0.016304347826086956,\n",
       " 'european': 0.03260869565217391,\n",
       " 'brown': 0.0,\n",
       " 'member': 0.03260869565217391,\n",
       " 'use': 0.016304347826086956,\n",
       " 'fuller': 0.016304347826086956,\n",
       " 'intens': 0.016304347826086956,\n",
       " 'final': 0.0,\n",
       " 'britain': 0.0,\n",
       " 'face': 0.0,\n",
       " 'back': 0.03260869565217391,\n",
       " 'read': 0.016304347826086956,\n",
       " 'europ': 0.016304347826086956,\n",
       " 'new': 0.03260869565217391,\n",
       " 'one': 0.04891304347826087,\n",
       " 'effect': 0.016304347826086956,\n",
       " 'deal': 0.0,\n",
       " 'sign': 0.0,\n",
       " 'freez': 0.0,\n",
       " 'internet': 0.016304347826086956,\n",
       " 'night': 0.0,\n",
       " 'talk': 0.0,\n",
       " 'begun': 0.0,\n",
       " 'direct': 0.06521739130434782,\n",
       " 'develop': 0.016304347826086956,\n",
       " 'chair': 0.0,\n",
       " 'fight': 0.016304347826086956,\n",
       " 'support': 0.03260869565217391,\n",
       " 'largest': 0.016304347826086956,\n",
       " 'permit': 0.016304347826086956,\n",
       " 'bank': 0.0,\n",
       " 'innov': 0.016304347826086956,\n",
       " 'reconstruct': 0.0,\n",
       " 'world': 0.0,\n",
       " 'concern': 0.016304347826086956,\n",
       " 'instruct': 0.0,\n",
       " 'small': 0.03260869565217391,\n",
       " 'say': 0.04891304347826087,\n",
       " 'protect': 0.03260869565217391,\n",
       " 'agreement': 0.0,\n",
       " 'germani': 0.0,\n",
       " 'ineffici': 0.016304347826086956,\n",
       " 'committe': 0.03260869565217391,\n",
       " 'number': 0.0,\n",
       " 'word': 0.016304347826086956,\n",
       " 'sourc': 0.016304347826086956,\n",
       " 'model': 0.016304347826086956,\n",
       " 'disast': 0.0,\n",
       " 'gordon': 0.0,\n",
       " 'group': 0.0,\n",
       " 'hit': 0.0,\n",
       " 'patent': 0.08152173913043478,\n",
       " 'vocal': 0.016304347826086956,\n",
       " 'first': 0.016304347826086956,\n",
       " 'meet': 0.016304347826086956,\n",
       " 'rule': 0.016304347826086956,\n",
       " 'decis': 0.016304347826086956,\n",
       " 'com': 0.016304347826086956,\n",
       " 'jack': 0.0,\n",
       " 'g': 0.0,\n",
       " 'believ': 0.0,\n",
       " 'draft': 0.04891304347826087,\n",
       " 'year': 0.0}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfbowA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def computeIDF(docList): #docList is a list\n",
    "    import math\n",
    "    idfDict = {}\n",
    "    N = len(docList) # get length of list\n",
    "    \n",
    "    idfDict = dict.fromkeys(docList[0].keys(), 0) # Assign 0 to first index in list\n",
    "    for doc in docList: # iterate over list\n",
    "        for word, val in doc.items(): #iterate over dictA and later dictB\n",
    "            if val > 0: # As long as \n",
    "                idfDict[word] += 1\n",
    "    \n",
    "    for word, val in idfDict.items():\n",
    "        idfDict[word] = math.log10(N / float(val))\n",
    "        \n",
    "    return idfDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "idfs = computeIDF([wordDictA, wordDictB])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def computeTFIDF(tfBow, idfs):\n",
    "    tfidf = {}\n",
    "    for word, val in tfBow.items():\n",
    "        tfidf[word] = val*idfs[word]\n",
    "    return tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidfBowA = computeTFIDF(tfbowA, idfs)\n",
    "tfidfBowB = computeTFIDF(tfbowB, idfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abstain</th>\n",
       "      <th>achiev</th>\n",
       "      <th>action</th>\n",
       "      <th>adopt</th>\n",
       "      <th>affair</th>\n",
       "      <th>affect</th>\n",
       "      <th>agre</th>\n",
       "      <th>agreement</th>\n",
       "      <th>also</th>\n",
       "      <th>amazon</th>\n",
       "      <th>...</th>\n",
       "      <th>vocal</th>\n",
       "      <th>vote</th>\n",
       "      <th>wealthi</th>\n",
       "      <th>week</th>\n",
       "      <th>welcom</th>\n",
       "      <th>without</th>\n",
       "      <th>word</th>\n",
       "      <th>world</th>\n",
       "      <th>would</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.006544</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.005845</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.002923</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.002923</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 201 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    abstain    achiev    action     adopt    affair    affect      agre  \\\n",
       "0  0.006544  0.006544  0.006544  0.006544  0.006544  0.000000  0.000000   \n",
       "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.002923  0.002923   \n",
       "\n",
       "   agreement      also    amazon  ...     vocal      vote   wealthi      week  \\\n",
       "0   0.000000  0.000000  0.006544  ...  0.006544  0.006544  0.000000  0.000000   \n",
       "1   0.002923  0.005845  0.000000  ...  0.000000  0.000000  0.002923  0.002923   \n",
       "\n",
       "     welcom   without      word     world  would      year  \n",
       "0  0.006544  0.006544  0.006544  0.000000    0.0  0.000000  \n",
       "1  0.000000  0.000000  0.000000  0.002923    0.0  0.002923  \n",
       "\n",
       "[2 rows x 201 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "pd.DataFrame([tfidfBowA, tfidfBowB])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## But yes, there is an easier way\n",
    "\n",
    "![big deal](https://media0.giphy.com/media/xUA7aQOxkz00lvCAOQ/giphy.gif?cid=3640f6095c2d7c51772f47644d09cc8b)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    abstain    achiev    action     adopt    affair    affect      agre  \\\n",
      "0  0.053285  0.053285  0.053285  0.053285  0.053285  0.000000  0.000000   \n",
      "1  0.000000  0.000000  0.000000  0.000000  0.000000  0.084167  0.084167   \n",
      "\n",
      "   agreement      also    amazon  ...     vocal      vote   wealthi      week  \\\n",
      "0   0.000000  0.000000  0.053285  ...  0.053285  0.053285  0.000000  0.000000   \n",
      "1   0.084167  0.168334  0.000000  ...  0.000000  0.000000  0.084167  0.084167   \n",
      "\n",
      "     welcom   without      word     world     would      year  \n",
      "0  0.053285  0.053285  0.053285  0.000000  0.113738  0.000000  \n",
      "1  0.000000  0.000000  0.000000  0.084167  0.059885  0.084167  \n",
      "\n",
      "[2 rows x 200 columns]\n"
     ]
    }
   ],
   "source": [
    "# create a string again\n",
    "cleaned_a = ' '.join(arta_stemmed)\n",
    "cleaned_b = ' '.join(artb_stemmed)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer()\n",
    "response = tfidf.fit_transform([cleaned_a, cleaned_b])\n",
    "\n",
    "import pandas as pd\n",
    "df = pd.DataFrame(response.toarray(), columns=tfidf.get_feature_names())\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Corpus Statistics \n",
    "\n",
    "How many non-zero elements are there?\n",
    "- Adapt the code below, using the `df` version of the `response` object to replace everywhere below it says `DATA`\n",
    "- Interpret the findings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Number of Non-Zero Elements in Vectorized Articles: 103.5\n",
      "Percentage of columns containing 0: 0.48250000000000004\n"
     ]
    }
   ],
   "source": [
    "# Edit code before running it\n",
    "import numpy as np\n",
    "\n",
    "new_val = np.array(df)\n",
    "\n",
    "non_zero_vals = np.count_nonzero(new_val) / float(df.shape[0])\n",
    "print(\"Average Number of Non-Zero Elements in Vectorized Articles: {}\".format(non_zero_vals))\n",
    "\n",
    "percent_sparse = 1 - (non_zero_vals / float(df.shape[1]))\n",
    "print('Percentage of columns containing 0: {}'.format(percent_sparse))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next Steps:\n",
    "- Create the tf-idf for the **whole** corpus of 12 articles\n",
    "- What are _on average_ the most important words in the whole corpus?\n",
    "- Add a column named \"Target\" to the dataset\n",
    "- Target will be set to 1 or 0 if the article is \"Politics\" or \"Not Politics\"\n",
    "- Do some exploratory analysis of the dataset\n",
    " - what are the average most important words for the \"Politics\" articles?\n",
    " - What are the average most important words for the \"Not Politics\"?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets talk classification\n",
    "- How would you split into train and test? what would be the dataset?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample code\n",
    "from sklearn.model_selection import train_test_split  \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
